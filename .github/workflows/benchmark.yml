name: üöÄ Performance Benchmarks

# Optimized benchmark tracking with performance regression detection
# Features:
# - Fast benchmarks by default (1s/1run) for quick feedback
# - Comprehensive mode available (5s/3runs) for detailed analysis
# - Isolated cache directories for self-hosted runners
# - Optional CPU/Memory profiling
# - Performance regression detection with alerts
# - Historical comparison and trend analysis
# - Automatic baseline updates on main branch

on:
  push:
    branches: [main] # Only run comprehensive benchmarks on main branch
  pull_request:
    branches: [main, develop] # Run on PRs to main/develop for regression detection
  workflow_run:
    workflows: ["üîß CI"] # Run after CI completes successfully to avoid duplication
    types:
      - completed
    branches: [main, develop, feature/*] # Run on feature branches only after CI passes
  workflow_dispatch: # Allow manual trigger for ad-hoc performance testing
    inputs:
      baseline_ref:
        description: "Git reference to use as baseline (default: main)"
        required: false
        default: "main"
        type: string
      benchmark_mode:
        description: "Benchmark mode: fast (1s/1run) or comprehensive (5s/3runs)"
        required: false
        default: "fast"
        type: choice
        options:
          - fast
          - comprehensive
      enable_profiling:
        description: "Enable CPU/Memory profiling (slower)"
        required: false
        default: false
        type: boolean

env:
  GO_VERSION: "1.24" # Keep consistent with ci.yml
  CACHE_VERSION: "v1" # Increment this to invalidate all caches
  BENCHMARK_TIME: "1s" # Fast benchmarks by default
  BENCHMARK_COUNT: "1" # Single run for speed

permissions:
  contents: read
  pull-requests: write # Required for PR comments
  actions: read
  checks: write

jobs:
  # Check if we should run benchmarks
  should-run:
    name: üîç Check if benchmarks should run
    runs-on: ubuntu-latest
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
    steps:
      - name: Check conditions
        id: check
        run: |
          echo "Event: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"

          # Always run on workflow_dispatch
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual trigger - running benchmarks"
            echo "should-run=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Always run on direct push to main
          if [ "${{ github.event_name }}" = "push" ] && [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "Push to main - running benchmarks"
            echo "should-run=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Always run on pull requests
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "Pull request - running benchmarks"
            echo "should-run=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # For workflow_run, only run if CI was successful
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
              echo "CI workflow successful - running benchmarks"
              echo "should-run=true" >> $GITHUB_OUTPUT
            else
              echo "CI workflow failed/cancelled - skipping benchmarks"
              echo "should-run=false" >> $GITHUB_OUTPUT
            fi
            exit 0
          fi

          # Default to not running
          echo "Condition not met - skipping benchmarks"
          echo "should-run=false" >> $GITHUB_OUTPUT

  benchmark:
    name: üèÅ Performance Benchmarks
    runs-on: ubuntu-latest
    needs: should-run
    if: needs.should-run.outputs.should-run == 'true'
    strategy:
      matrix:
        # Test on different architectures for comprehensive performance analysis
        include:
          - os: ubuntu-latest
            goarch: amd64
            label: "Linux AMD64"
    steps:
      - name: üì• Checkout current code
        uses: actions/checkout@v4
        with:
          # For workflow_run events, checkout the head SHA of the triggering workflow
          ref: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.head_sha || github.sha }}
          fetch-depth: 0 # Fetch full history for baseline comparison

      - name: üîß Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: ÔøΩ Configure Go cache directories
        run: |
          # Create unique workspace identifier for benchmark job
          MATRIX_ID="bench-${{ matrix.goarch }}-${{ github.run_id }}-${{ github.run_attempt }}"

          # Set unique cache directories for this benchmark job
          export GOCACHE="$HOME/.cache/go-build-${MATRIX_ID}"
          export GOMODCACHE="$HOME/go/pkg/mod-${MATRIX_ID}"
          export GOPATH="$HOME/go-${MATRIX_ID}"
          export GOBIN="${GOPATH}/bin"

          echo "GOCACHE=${GOCACHE}" >> $GITHUB_ENV
          echo "GOMODCACHE=${GOMODCACHE}" >> $GITHUB_ENV
          echo "GOPATH=${GOPATH}" >> $GITHUB_ENV
          echo "GOBIN=${GOBIN}" >> $GITHUB_ENV
          echo "MATRIX_ID=${MATRIX_ID}" >> $GITHUB_ENV

          mkdir -p "${GOCACHE}" "${GOMODCACHE}" "${GOPATH}" "${GOBIN}"

          echo "‚úÖ Benchmark Go cache directories configured for ${MATRIX_ID}:"
          echo "  GOCACHE: ${GOCACHE}"
          echo "  GOMODCACHE: ${GOMODCACHE}"
          echo "  GOPATH: ${GOPATH}"
          echo "  GOBIN: ${GOBIN}"

      - name: ÔøΩüíæ Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/go-bench-${{ matrix.goarch }}-${{ github.run_id }}-${{ github.run_attempt }}
          key: ${{ env.CACHE_VERSION }}-${{ runner.os }}-go-bench-${{ matrix.goarch }}-${{ github.run_id }}-${{ github.run_attempt }}-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ env.CACHE_VERSION }}-${{ runner.os }}-go-bench-${{ matrix.goarch }}-
            ${{ env.CACHE_VERSION }}-${{ runner.os }}-go-bench-
            ${{ env.CACHE_VERSION }}-${{ runner.os }}-go-

      - name: üì¶ Download dependencies
        run: go mod download

      - name: üîß Install benchmark tools
        run: |
          echo "Installing benchmark analysis tools to isolated GOBIN..."
          go install golang.org/x/perf/cmd/benchstat@latest
          go install golang.org/x/perf/cmd/benchfilter@latest

          echo "‚úÖ Installed benchmark tools:"
          echo "  - benchstat: Statistical analysis and A/B comparisons"
          echo "  - benchfilter: Benchmark result filtering"

      - name: üèÉ Run current benchmarks
        env:
          GOARCH: ${{ matrix.goarch }}
        run: |
          # Set benchmark parameters based on input or defaults
          if [ "${{ github.event.inputs.benchmark_mode }}" = "comprehensive" ]; then
            BENCH_TIME="5s"
            BENCH_COUNT="3"
            MODE_LABEL="Comprehensive"
          else
            BENCH_TIME="1s"
            BENCH_COUNT="1"
            MODE_LABEL="Fast"
          fi

          # Enable profiling based on input
          if [ "${{ github.event.inputs.enable_profiling }}" = "true" ] || [ "${{ github.event.inputs.benchmark_mode }}" = "comprehensive" ]; then
            ENABLE_PROFILING="true"
          else
            ENABLE_PROFILING="false"
          fi

          echo "üöÄ Running ${MODE_LABEL} benchmarks for ${{ matrix.label }}..."
          echo "‚è±Ô∏è  Benchmark time: ${BENCH_TIME}, Count: ${BENCH_COUNT}"

          # Create results directory
          mkdir -p benchmark-results

          # Run main benchmarks with configurable parameters
          echo "Running benchmark suite..."
          go test -bench=. -benchmem -benchtime=${BENCH_TIME} -count=${BENCH_COUNT} ./... | tee "benchmark-results/current-${{ matrix.goarch }}.txt"

          # Conditional profiling (only if enabled)
          if [ "${ENABLE_PROFILING}" = "true" ]; then
            echo "üî¨ Running benchmarks with profiling (this may take longer)..."
            
            # CPU profiling
            echo "  - CPU profiling..."
            go test -bench=. -benchmem -benchtime=${BENCH_TIME} -cpuprofile="benchmark-results/cpu-${{ matrix.goarch }}.prof" ./... > /dev/null 2>&1 || true

            # Memory profiling
            echo "  - Memory profiling..."
            go test -bench=. -benchmem -benchtime=${BENCH_TIME} -memprofile="benchmark-results/mem-${{ matrix.goarch }}.prof" ./... > /dev/null 2>&1 || true
            
            echo "‚úÖ Profiling completed"
          else
            echo "‚è≠Ô∏è  Profiling skipped (use comprehensive mode or enable profiling to include)"
          fi

          # Generate benchmark statistics
          echo "üìä Current benchmark summary for ${{ matrix.label }}:"
          echo "================================================================"
          cat "benchmark-results/current-${{ matrix.goarch }}.txt" | grep "^Benchmark" | head -10
          echo "================================================================"

      - name: üì• Get baseline benchmarks
        id: baseline
        run: |
          BASELINE_REF="${{ github.event.inputs.baseline_ref || 'main' }}"

          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASELINE_REF="${{ github.base_ref }}"
          fi

          echo "baseline_ref=$BASELINE_REF" >> $GITHUB_OUTPUT
          echo "üîç Getting baseline benchmarks..."

          # Current branch/commit info
          current_branch=$(git branch --show-current)
          current_commit=$(git rev-parse HEAD)

          echo "Current branch: $current_branch"
          echo "Current commit: $current_commit"
          echo "Target baseline: $BASELINE_REF"

          # Strategy 1: Try to use existing baseline file from repository
          if [ -f ".github/benchmark-baselines/baseline-${{ matrix.goarch }}.txt" ] && [ -s ".github/benchmark-baselines/baseline-${{ matrix.goarch }}.txt" ]; then
            echo "‚úÖ Found existing baseline file in repository"
            cp ".github/benchmark-baselines/baseline-${{ matrix.goarch }}.txt" "benchmark-results/baseline-${{ matrix.goarch }}.txt"
            echo "has_baseline=true" >> $GITHUB_OUTPUT
            echo "baseline_source=repository" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Strategy 2: If we're on the baseline branch already, skip baseline comparison
          if [ "$current_branch" = "$BASELINE_REF" ] || [ "${{ github.ref }}" = "refs/heads/$BASELINE_REF" ]; then
            echo "üìù Already on target baseline branch ($BASELINE_REF), skipping baseline comparison"
            echo "This run will establish new baseline after completion"
            touch "benchmark-results/baseline-${{ matrix.goarch }}.txt"
            echo "has_baseline=false" >> $GITHUB_OUTPUT
            echo "baseline_source=none" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Strategy 3: Try to checkout the baseline branch/commit
          echo "üîÑ Attempting to checkout baseline: $BASELINE_REF"

          # Try different checkout strategies
          checkout_success=false

          # Try 1: Direct checkout
          if git checkout "$BASELINE_REF" 2>/dev/null; then
            echo "‚úÖ Successfully checked out $BASELINE_REF"
            checkout_success=true
          # Try 2: Checkout with origin prefix  
          elif git checkout "origin/$BASELINE_REF" 2>/dev/null; then
            echo "‚úÖ Successfully checked out origin/$BASELINE_REF"
            checkout_success=true
          # Try 3: Fetch and checkout
          elif git fetch origin "$BASELINE_REF:$BASELINE_REF" 2>/dev/null && git checkout "$BASELINE_REF" 2>/dev/null; then
            echo "‚úÖ Successfully fetched and checked out $BASELINE_REF"
            checkout_success=true
          fi

          if [ "$checkout_success" = true ]; then
            echo "üèÉ Running baseline benchmarks on $BASELINE_REF..."
            
            # Use same timing as current benchmarks
            if [ "${{ github.event.inputs.benchmark_mode }}" = "comprehensive" ]; then
              BENCH_TIME="5s"
              BENCH_COUNT="3"
            else
              BENCH_TIME="1s"
              BENCH_COUNT="1"
            fi
            
            go test -bench=. -benchmem -benchtime=${BENCH_TIME} -count=${BENCH_COUNT} ./... | tee "benchmark-results/baseline-${{ matrix.goarch }}.txt" || true
            
            # Return to current commit
            echo "üîÑ Returning to original commit: $current_commit"
            git checkout "$current_commit"
            
            echo "has_baseline=true" >> $GITHUB_OUTPUT
            echo "baseline_source=branch" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è Could not checkout $BASELINE_REF using any strategy"
            echo "Proceeding without baseline comparison"
            touch "benchmark-results/baseline-${{ matrix.goarch }}.txt"
            echo "has_baseline=false" >> $GITHUB_OUTPUT
            echo "baseline_source=none" >> $GITHUB_OUTPUT
          fi

      - name: üìä Generate performance analysis
        id: analysis
        if: steps.baseline.outputs.has_baseline == 'true'
        env:
          GOARCH: ${{ matrix.goarch }}
        run: |
          echo "üî¨ Analyzing performance changes for ${{ matrix.label }}..."

          # Generate statistical comparison
          if [ -f "benchmark-results/baseline-${{ matrix.goarch }}.txt" ] && [ -s "benchmark-results/baseline-${{ matrix.goarch }}.txt" ]; then
            echo "üìà Statistical analysis using benchstat..."
            
            # Filter benchmarks for cleaner analysis (remove PASS/FAIL lines)
            echo "üîß Filtering benchmark data for analysis..."
            benchfilter "*" "benchmark-results/baseline-${{ matrix.goarch }}.txt" > "benchmark-results/baseline-filtered-${{ matrix.goarch }}.txt" 2>/dev/null || cp "benchmark-results/baseline-${{ matrix.goarch }}.txt" "benchmark-results/baseline-filtered-${{ matrix.goarch }}.txt"
            benchfilter "*" "benchmark-results/current-${{ matrix.goarch }}.txt" > "benchmark-results/current-filtered-${{ matrix.goarch }}.txt" 2>/dev/null || cp "benchmark-results/current-${{ matrix.goarch }}.txt" "benchmark-results/current-filtered-${{ matrix.goarch }}.txt"
            
            # Run benchstat on filtered data
            benchstat "benchmark-results/baseline-filtered-${{ matrix.goarch }}.txt" "benchmark-results/current-filtered-${{ matrix.goarch }}.txt" | tee "benchmark-results/comparison-${{ matrix.goarch }}.txt"
            
            # Check for regressions (>10% performance decrease)
            echo "üîç Checking for performance regressions..."
            
            REGRESSIONS=$(grep -E "~|%" "benchmark-results/comparison-${{ matrix.goarch }}.txt" | grep -E "\+[0-9]+\.[0-9]+%" | wc -l || echo "0")
            IMPROVEMENTS=$(grep -E "~|%" "benchmark-results/comparison-${{ matrix.goarch }}.txt" | grep -E "\-[0-9]+\.[0-9]+%" | wc -l || echo "0")
            
            # Check for significant regressions (>50%)
            CRITICAL_REGRESSIONS=$(grep -E "~|%" "benchmark-results/comparison-${{ matrix.goarch }}.txt" | grep -E "\+[5-9][0-9]\.[0-9]+%|\+[0-9]{3,}\.[0-9]+%" | wc -l || echo "0")
            
            echo "regressions=$REGRESSIONS" >> $GITHUB_OUTPUT
            echo "improvements=$IMPROVEMENTS" >> $GITHUB_OUTPUT
            echo "critical_regressions=$CRITICAL_REGRESSIONS" >> $GITHUB_OUTPUT
            
            # Create enhanced summary
            {
              echo "## üèÅ Benchmark Results Summary - ${{ matrix.label }}"
              echo ""
              echo "**Performance Changes:**"
              echo "- üî¥ Regressions detected: $REGRESSIONS"
              echo "- üü¢ Improvements detected: $IMPROVEMENTS"
              if [ "$CRITICAL_REGRESSIONS" -gt 0 ]; then
                echo "- üö® **Critical regressions (>50%)**: $CRITICAL_REGRESSIONS"
              fi
              echo ""
              echo "### üìä Detailed Statistical Analysis"
              echo "\`\`\`"
              cat "benchmark-results/comparison-${{ matrix.goarch }}.txt"
              echo "\`\`\`"
              echo ""
              echo "### üìà Current Benchmark Results (Top 20)"
              echo "\`\`\`"
              grep "^Benchmark" "benchmark-results/current-${{ matrix.goarch }}.txt" | head -20
              echo "\`\`\`"
              
              # Add performance insights
              echo ""
              echo "### üîç Performance Insights"
              if [ "$CRITICAL_REGRESSIONS" -gt 0 ]; then
                echo "‚ö†Ô∏è **Critical Performance Issues Detected!**"
                echo ""
                echo "The following benchmarks show severe performance regressions (>50%):"
                echo "\`\`\`"
                grep -E "\+[5-9][0-9]\.[0-9]+%|\+[0-9]{3,}\.[0-9]+%" "benchmark-results/comparison-${{ matrix.goarch }}.txt" | head -5
                echo "\`\`\`"
                echo ""
              fi
              
              if [ "$IMPROVEMENTS" -gt 0 ]; then
                echo "‚úÖ **Performance Improvements:**"
                echo "\`\`\`"
                grep -E "\-[0-9]+\.[0-9]+%" "benchmark-results/comparison-${{ matrix.goarch }}.txt" | head -5
                echo "\`\`\`"
                echo ""
              fi
            } > "benchmark-results/summary-${{ matrix.goarch }}.md"
            
            echo "has_comparison=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è No baseline data available for comparison"
            echo "has_comparison=false" >> $GITHUB_OUTPUT
            echo "regressions=0" >> $GITHUB_OUTPUT
            echo "improvements=0" >> $GITHUB_OUTPUT
            
            # Create summary without comparison
            {
              echo "## üèÅ Benchmark Results - ${{ matrix.label }}"
              echo ""
              echo "**Status:** Baseline benchmarks not available for comparison"
              echo ""
              echo "### üìà Current Benchmark Results"
              echo "\`\`\`"
              grep "^Benchmark" "benchmark-results/current-${{ matrix.goarch }}.txt" | head -20
              echo "\`\`\`"
            } > "benchmark-results/summary-${{ matrix.goarch }}.md"
          fi

      - name: üì§ Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.goarch }}
          path: |
            benchmark-results/
          retention-days: 30

      - name: ‚ö†Ô∏è Check for performance issues
        if: steps.analysis.outputs.regressions != '0' && steps.analysis.outputs.regressions != ''
        run: |
          REGRESSIONS="${{ steps.analysis.outputs.regressions }}"
          CRITICAL="${{ steps.analysis.outputs.critical_regressions }}"

          if [ "$CRITICAL" != "0" ] && [ "$CRITICAL" != "" ]; then
            echo "üö® CRITICAL: Severe performance regressions detected!"
            echo "Number of critical regressions (>50%): $CRITICAL"
            echo "Total regressions: $REGRESSIONS"
            echo ""
            echo "‚ö†Ô∏è  IMMEDIATE ACTION REQUIRED:"
            echo "- Review the affected benchmark functions"
            echo "- Consider reverting recent changes"
            echo "- Profile the code to identify bottlenecks"
            echo ""
            echo "::error title=Critical Performance Regression::$CRITICAL severe benchmark regressions (>50%) detected for ${{ matrix.label }}"
          else
            echo "‚ö†Ô∏è Performance regressions detected"
            echo "Number of regressions: $REGRESSIONS"
            echo ""
            echo "Please review the benchmark comparison above."
            echo "Consider optimizing the affected code paths."
            echo ""
            echo "::warning title=Performance Regression::$REGRESSIONS benchmark regressions detected for ${{ matrix.label }}"
          fi

      - name: üßπ Cleanup benchmark cache (self-hosted)
        if: always()
        run: |
          echo "üßπ Cleaning up benchmark cache directories..."

          # Clean up this job's isolated cache directories
          MATRIX_ID="bench-${{ matrix.goarch }}-${{ github.run_id }}-${{ github.run_attempt }}"

          # Remove isolated directories for this specific benchmark job
          rm -rf "$HOME/.cache/go-build-${MATRIX_ID}" 2>/dev/null || true
          rm -rf "$HOME/go/pkg/mod-${MATRIX_ID}" 2>/dev/null || true  
          rm -rf "$HOME/go-${MATRIX_ID}" 2>/dev/null || true

          echo "‚úÖ Benchmark cache cleanup completed for ${MATRIX_ID}"

  # Combine results and post PR comment
  benchmark-summary:
    name: üìã Benchmark Summary
    needs: benchmark
    runs-on: ubuntu-latest
    if: always() && github.event_name == 'pull_request'
    steps:
      - name: üì• Download all benchmark results
        uses: actions/download-artifact@v4
        with:
          path: all-results

      - name: üîç Combine results and create PR comment
        run: |
          echo "üìä Creating comprehensive benchmark summary..."

          # Initialize summary
          {
            echo "# üöÄ Benchmark Performance Report"
            echo ""
            echo "**Workflow:** \`${{ github.workflow }}\` | **Run:** [\`${{ github.run_id }}\`](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})"
            echo "**Commit:** \`${{ github.sha }}\` | **Branch:** \`${{ github.head_ref }}\`"
            echo ""
          } > pr-comment.md

          # Add results for each architecture
          total_regressions=0
          total_improvements=0
          total_critical=0

          for arch_dir in all-results/benchmark-results-*; do
            if [ -d "$arch_dir" ]; then
              arch=$(basename "$arch_dir" | sed 's/benchmark-results-//')
              echo "Processing results for $arch..."
              
              if [ -f "$arch_dir/summary-$arch.md" ]; then
                echo "" >> pr-comment.md
                cat "$arch_dir/summary-$arch.md" >> pr-comment.md
                echo "" >> pr-comment.md
                
                # Count regressions and improvements (enhanced parsing)
                if [ -f "$arch_dir/comparison-$arch.txt" ]; then
                  arch_regressions=$(grep -E "\+[0-9]+\.[0-9]+%" "$arch_dir/comparison-$arch.txt" | wc -l || echo "0")
                  arch_improvements=$(grep -E "\-[0-9]+\.[0-9]+%" "$arch_dir/comparison-$arch.txt" | wc -l || echo "0")
                  arch_critical=$(grep -E "\+[5-9][0-9]\.[0-9]+%|\+[0-9]{3,}\.[0-9]+%" "$arch_dir/comparison-$arch.txt" | wc -l || echo "0")
                  
                  total_regressions=$((total_regressions + arch_regressions))
                  total_improvements=$((total_improvements + arch_improvements))
                  total_critical=$((total_critical + arch_critical))
                fi
              fi
            fi
          done

          # Add footer with enhanced summary
          {
            echo "---"
            echo ""
            echo "### üìà Overall Performance Summary"
            echo "- **Total Regressions:** $total_regressions"
            echo "- **Total Improvements:** $total_improvements"
            if [ $total_critical -gt 0 ]; then
              echo "- **üö® Critical Regressions (>50%):** $total_critical"
            fi
            echo ""
            if [ $total_critical -gt 0 ]; then
              echo "üö® **CRITICAL:** Severe performance regressions detected!"
              echo ""
              echo "**Immediate action required:**"
              echo "- Review and optimize critical performance paths"
              echo "- Consider reverting recent changes"
              echo "- Run profiling to identify bottlenecks"
            elif [ $total_regressions -gt 0 ]; then
              echo "‚ö†Ô∏è **Action Required:** Performance regressions detected. Please review and optimize."
            else
              echo "‚úÖ **Excellent!** No performance regressions detected."
              if [ $total_improvements -gt 0 ]; then
                echo "üéâ **Bonus:** Performance improvements detected!"
              fi
            fi
            echo ""
            echo "üìù *This comment will be updated automatically when new commits are pushed.*"
            echo ""
            echo "<!-- benchmark-comment-marker -->"
          } >> pr-comment.md

          echo "Generated PR comment:"
          echo "=========================="
          cat pr-comment.md
          echo "=========================="

      - name: üí¨ Post/Update PR comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('pr-comment.md', 'utf8');

            // Find existing comment
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.data.find(c => 
              c.body.includes('<!-- benchmark-comment-marker -->')
            );

            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
              console.log('Updated existing benchmark comment');
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
              console.log('Created new benchmark comment');
            }

  # Update baseline benchmarks on main branch
  update-baseline:
    name: üìö Update Baseline
    needs: benchmark
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: üì• Download benchmark results
        uses: actions/download-artifact@v4
        with:
          path: baseline-update

      - name: üìö Store baseline benchmarks
        run: |
          echo "üìö Updating baseline benchmarks for future comparisons..."

          # Create baseline directory
          mkdir -p .github/benchmark-baselines

          # Copy current results as new baselines
          for arch_dir in baseline-update/benchmark-results-*; do
            if [ -d "$arch_dir" ]; then
              arch=$(basename "$arch_dir" | sed 's/benchmark-results-//')
              echo "Updating baseline for $arch..."
              
              if [ -f "$arch_dir/current-$arch.txt" ]; then
                cp "$arch_dir/current-$arch.txt" ".github/benchmark-baselines/baseline-$arch.txt"
                echo "‚úÖ Updated baseline for $arch"
              fi
            fi
          done

          # Create metadata
          {
            echo "# Benchmark Baseline Metadata"
            echo "Updated: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
            echo "Commit: ${{ github.sha }}"
            echo "Workflow: ${{ github.run_id }}"
          } > .github/benchmark-baselines/metadata.txt

          echo "üìö Baseline update completed"

      - name: üíæ Commit baseline updates
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          if [ -n "$(git status --porcelain)" ]; then
            git add .github/benchmark-baselines/
            git commit -m "üîÑ Update benchmark baselines [skip ci]
            
            Auto-updated from commit ${{ github.sha }}
            Workflow run: ${{ github.run_id }}"
            git push
            echo "‚úÖ Pushed baseline updates"
          else
            echo "üìù No changes to commit"
          fi
